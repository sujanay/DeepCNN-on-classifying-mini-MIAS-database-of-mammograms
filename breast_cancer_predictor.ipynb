{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author**: Sujan Tamang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breast Cancer Predictor\n",
    "This work uses the mammogram image dataset from [mini-MIAS](http://peipa.essex.ac.uk/info/mias.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras.applications import VGG16\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "image_size = 224      # Test Image Size\n",
    "test_batchsize = 16    # Test Batch Size\n",
    "train_batchsize = 8   # Change the batchsize according to your system RAM\n",
    "val_batchsize = 8     # Validation Batch Size\n",
    "epochs = 20\n",
    "show_errors = \"TRUE\"\n",
    "show_correct_predictions = \"FALSE\"\n",
    "\n",
    "# Image Dataset Directory\n",
    "train_dir = \"dataset/train/\"\n",
    "validation_dir = \"dataset/valid/\"\n",
    "test_dir = \"dataset/test/\"\n",
    "\n",
    "\n",
    "def vgg16_finetuned():\n",
    "    # Load the VGG model\n",
    "    vgg_conv = VGG16(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "    # Freeze all the layers except the last 4 layers\n",
    "    for layer in vgg_conv.layers[:-4]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Check the trainable status of the individual layers\n",
    "    # for layer in vgg_conv.layers:\n",
    "    #     print(layer, layer.trainable)\n",
    "\n",
    "    # Create a Sequential model\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # Add the vgg convolutional base model to the Sequential model\n",
    "    model.add(vgg_conv)\n",
    "\n",
    "    # Add new layers\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1024, activation=\"relu\"))\n",
    "    model.add(layers.Dropout(0.8))\n",
    "    model.add(layers.Dense(2, activation=\"softmax\"))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_graphs(history):\n",
    "    # Plot the accuracy and loss curves\n",
    "    acc = history.history[\"acc\"]\n",
    "    val_acc = history.history[\"val_acc\"]\n",
    "    loss = history.history[\"loss\"]\n",
    "    val_loss = history.history[\"val_loss\"]\n",
    "\n",
    "    epochs1 = range(len(acc))\n",
    "\n",
    "    plt.plot(epochs1, acc, \"b\", label=\"Training acc\")\n",
    "    plt.plot(epochs1, val_acc, \"r\", label=\"Validation acc\")\n",
    "    plt.title(\"Training and validation accuracy\")\n",
    "    plt.legend()\n",
    "    plt.savefig(\"Training and validation accuracy\")\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(epochs1, loss, \"b\", label=\"Training loss\")\n",
    "    plt.plot(epochs1, val_loss, \"r\", label=\"Validation loss\")\n",
    "    plt.title(\"Training and validation loss\")\n",
    "    plt.legend()\n",
    "    plt.savefig(\"Training and validation loss\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 72 images belonging to 2 classes.\n",
      "Found 16 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1. / 255,\n",
    "                                   rotation_range=20,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode=\"nearest\")\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    target_size=(224, 224),\n",
    "                                                    batch_size=train_batchsize,\n",
    "                                                    class_mode=\"categorical\")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "validation_generator = validation_datagen.flow_from_directory(validation_dir,\n",
    "                                                              target_size=(224, 224),\n",
    "                                                              batch_size=val_batchsize,\n",
    "                                                              class_mode=\"categorical\",\n",
    "                                                              shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = vgg16_finetuned()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/20\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.7691 - acc: 0.5840WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10 batches). You may need to use the repeat() function when building your dataset.\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.7787 - acc: 0.5770 - val_loss: 0.7983 - val_acc: 0.3750\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.37500, saving model to trained_models/vgg16_1.h5\n",
      "Epoch 2/20\n",
      "9/9 [==============================] - 9s 1s/step - loss: 0.8871 - acc: 0.4116\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n",
      "Epoch 3/20\n",
      "9/9 [==============================] - 10s 1s/step - loss: 0.6942 - acc: 0.6426\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n",
      "Epoch 4/20\n",
      "9/9 [==============================] - 10s 1s/step - loss: 0.8584 - acc: 0.5408\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n",
      "Epoch 5/20\n",
      "9/9 [==============================] - 10s 1s/step - loss: 0.7844 - acc: 0.4701\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n",
      "Epoch 6/20\n",
      "9/9 [==============================] - 10s 1s/step - loss: 0.8095 - acc: 0.6294\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n",
      "Epoch 7/20\n",
      "9/9 [==============================] - 10s 1s/step - loss: 0.8397 - acc: 0.5423\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n",
      "Epoch 8/20\n",
      "3/9 [=========>....................] - ETA: 6s - loss: 0.5964 - acc: 0.6528"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(\"trained_models/vgg16_1.h5\", \n",
    "                             monitor=\"val_acc\", \n",
    "                             verbose=1, \n",
    "                             save_best_only=True, \n",
    "                             save_weights_only=False, \n",
    "                             mode=\"auto\", \n",
    "                             period=1)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor=\"val_acc\", \n",
    "                               min_delta=0, \n",
    "                               patience=20, \n",
    "                               verbose=1, \n",
    "                               mode=\"auto\")\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(lr=1e-5), metrics=[\"acc\"])\n",
    "history = model.fit(train_generator,\n",
    "                    validation_data= validation_generator, \n",
    "                    validation_steps=10,\n",
    "                    epochs=epochs,\n",
    "                    callbacks=[checkpoint, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_graphs(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
